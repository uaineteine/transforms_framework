name: Unit Tests

on:
  workflow_dispatch:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  unit_tests:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'
      - name: Setup Hadoop for Windows
        run: |
          mkdir C:\hadoop\bin -Force
          # Use a more reliable winutils source
          Invoke-WebRequest -Uri "https://github.com/steveloughran/winutils/raw/master/hadoop-3.0.0/bin/winutils.exe" -OutFile "C:\hadoop\bin\winutils.exe"
          Invoke-WebRequest -Uri "https://github.com/steveloughran/winutils/raw/master/hadoop-3.0.0/bin/hadoop.dll" -OutFile "C:\hadoop\bin\hadoop.dll"
          echo "HADOOP_HOME=C:\hadoop" >> $env:GITHUB_ENV
          echo "C:\hadoop\bin" >> $env:GITHUB_PATH
          # Create temp directory for Spark
          mkdir C:\tmp\hive -Force
          # Grant permissions
          icacls C:\hadoop /grant Everyone:F /T
          icacls C:\tmp /grant Everyone:F /T
        shell: pwsh
      - name: Install custom packages
        run: |
          python -m pip install --upgrade pip
          pip install -r custom_packages.txt
      - name: Install requirements
        run: |
          pip install -r requirements.txt
      - name: Set Spark environment variables
        run: |
          echo "SPARK_LOCAL_IP=127.0.0.1" >> $env:GITHUB_ENV
        shell: pwsh
      - name: Verify environment setup
        run: |
          Write-Host "=== Environment Verification ==="
          Write-Host "Python: $(python --version)"
          Write-Host "Python Path: $(python -c 'import sys; print(sys.executable)')"
          Write-Host "Java: $(java -version 2>&1 | Select-Object -First 1)"
          Write-Host "HADOOP_HOME: $env:HADOOP_HOME"
          Write-Host "PATH contains hadoop\bin: $($env:PATH -like '*hadoop\bin*')"
          Write-Host "Hadoop binaries:"
          Get-ChildItem C:\hadoop\bin | Format-Table Name, Length
          Write-Host "PySpark version:"
          python -c "import pyspark; print(f'PySpark {pyspark.__version__}')"
          Write-Host "=== End Verification ==="
        shell: pwsh
      - name: Run unit tests
        shell: cmd
        run: |
          run_unit_test.bat
      - name: Check exit code and display summary
        if: always()
        run: |
          Write-Host "=== Test Execution Summary ==="
          Write-Host "Exit Code: $LASTEXITCODE"
          if (Test-Path "tests\test_log.txt") {
            Write-Host "`n=== Last 50 lines of test log ==="
            Get-Content "tests\test_log.txt" -Tail 50
          }
          if (Test-Path "templates\transform_dag_job_run1.html") {
            Write-Host "`n=== DAG report generated successfully ==="
          }
          Write-Host "=== End Summary ==="
        shell: pwsh
      - name: Upload test results as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: tests/test_log.txt
          if-no-files-found: warn
          retention-days: 14
      - name: Upload DAG report as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dag-report
          path: templates/transform_dag_job_run1.html
          if-no-files-found: warn
          retention-days: 14
