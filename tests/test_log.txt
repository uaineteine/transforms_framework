 
 
================================================================================ 
Running: save_raw_text.py 
================================================================================ 
 
WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
TEST WORKING
SUCCESS: The process with PID 3356 (child process of PID 22188) has been terminated.
SUCCESS: The process with PID 22188 (child process of PID 2640) has been terminated.
SUCCESS: The process with PID 2640 (child process of PID 23096) has been terminated.
 
 
================================================================================ 
Running: list_transforms.py 
================================================================================ 
 
[hash_lib] importing base classes
[hash_lib] import complete

 Transforms Library: 24 transforms available
   Use listatomic() to see all available transforms in a table format.


 Macro Library: 4 macro transforms available
   Use listmacro() to see all available macro transforms in a table format.

Total macros found: 4
Total transforms found: 24
 
 
================================================================================ 
Running: load_resources.py 
================================================================================ 
 
WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Starting test pipeline execution at Sat Jan 24 03:06:23 2026
Creating Spark session
Current setup engine is: pyspark
Using provided Spark session. Engine set to pyspark.
Setting environment variable: TNSFRMS_JOB_ID=-1
Setting environment variable: TNSFRMS_RUN_ID=-1
Setting environment variable: TNSFRMS_PROD=prod
Setting environment variable: TNSFRMS_LOG_LOC=jobs/{prodtest}/job_{job_id}/treatments.json
Setting environment variable: TNSFRMS_OUT_TABLE_LOC=jobs/{prodtest}/job_{job_id}
Setting environment variable: TNSFRMS_SRC_VAR=src_id
Setting environment variable: TNSFRMS_SYN_VAR=syn_id
Setting environment variable: TNSFRMS_ID_VAR=per_id
Setting environment variable: TNSFRMS_IDMAPS_LOC=../tests/test_tables/id_maps
Setting environment variable: TNSFRMS_JOB_STATE=../tests/test_tables/jobs/{prodtest}/job_{job_id}/setup/run_state.json
Setting environment variable: TNSFRMS_JOB_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/{tablename}.json
Setting environment variable: TNSFRMS_JOB_COLS_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_columns.csv
Setting environment variable: TNSFRMS_TABLE_SUMMARY_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_table_summary.csv
Setting environment variable: TNSFRMS_SUPPLY_LOAD_FORMAT=csv
Setting environment variable: TNSFRMS_ID_MOD=id_mod
Setting environment variable: TNSFRMS_TAR_PART_SIZE=268435456
Setting environment variable: HASH_METHOD_LOC=hash_keys
Setting environment variable: TNSFRMS_RES_LOC=../tests/test_tables/resources/{prodtest}/dss_entity_map_view/id_group={id_group}
Setting environment variable: TNSFRMS_RES_TYPE=csv
Default environment variables have been set where necessary.
Production/Test mode set to: prod
TEST LOADING ENTITY MAP FOR ID GROUP 1
+-----------+------+--------------+--------------+-----------------+
|id_group_cd|src_id|syn_id_refresh|syn_id_interim|post_worm_cutover|
+-----------+------+--------------+--------------+-----------------+
|          1|     1|            14|           141|            false|
|          1|     3|            33|           331|             true|
|          1|     2|            22|           221|            false|
+-----------+------+--------------+--------------+-----------------+

TEST LOADING ENTITY MAP FOR ID GROUPS 1 and 2
+-----------+------+--------------+--------------+-----------------+
|id_group_cd|src_id|syn_id_refresh|syn_id_interim|post_worm_cutover|
+-----------+------+--------------+--------------+-----------------+
|          1|     1|            14|           141|            false|
|          1|     3|            33|           331|             true|
|          1|     2|            22|           221|            false|
|          2|     3|            31|           313|             true|
|          2|     1|            12|           114|            false|
|          2|     2|            21|           212|            false|
+-----------+------+--------------+--------------+-----------------+

TEST LOADING ENTITY MAP WITH STRING AND INT IDS 3 and 2
+-----------+--------+--------------+--------------+-----------------+
|id_group_cd|  src_id|syn_id_refresh|syn_id_interim|post_worm_cutover|
+-----------+--------+--------------+--------------+-----------------+
|          2|       3|            31|           313|             true|
|          2|       1|            12|           114|            false|
|          2|       2|            21|           212|            false|
|          3|John Doe|           101|          1011|            false|
|          3|  Twiggy|           303|          3031|            false|
+-----------+--------+--------------+--------------+-----------------+

TEST LOADING ENTITY MAP TO AVOID DUPLICATES
No duplicates found after loading entity map with duplicate ID groups
TEST COMPLETE
Spark session stopped successfully
SUCCESS: The process with PID 24032 (child process of PID 4332) has been terminated.
SUCCESS: The process with PID 4332 (child process of PID 22224) has been terminated.
SUCCESS: The process with PID 22224 (child process of PID 22108) has been terminated.
 
 
================================================================================ 
Running: template_pipe.py 
================================================================================ 
 
WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
System.Management.Automation.RemoteException
[Stage 1:>                                                          (0 + 1) / 1]
System.Management.Automation.RemoteException
Starting test pipeline execution at Sat Jan 24 03:06:45 2026
Creating Spark session
Current setup engine is: pyspark
Using provided Spark session. Engine set to pyspark.
Setting environment variable: TNSFRMS_JOB_ID=-1
Setting environment variable: TNSFRMS_RUN_ID=-1
Setting environment variable: TNSFRMS_PROD=prod
Setting environment variable: TNSFRMS_LOG_LOC=jobs/{prodtest}/job_{job_id}/treatments.json
Setting environment variable: TNSFRMS_OUT_TABLE_LOC=jobs/{prodtest}/job_{job_id}
Setting environment variable: TNSFRMS_SRC_VAR=src_id
Setting environment variable: TNSFRMS_SYN_VAR=syn_id
Setting environment variable: TNSFRMS_ID_VAR=per_id
Setting environment variable: TNSFRMS_IDMAPS_LOC=../tests/test_tables/id_maps
Setting environment variable: TNSFRMS_JOB_STATE=../tests/test_tables/jobs/{prodtest}/job_{job_id}/setup/run_state.json
Setting environment variable: TNSFRMS_JOB_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/{tablename}.json
Setting environment variable: TNSFRMS_JOB_COLS_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_columns.csv
Setting environment variable: TNSFRMS_TABLE_SUMMARY_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_table_summary.csv
Setting environment variable: TNSFRMS_SUPPLY_LOAD_FORMAT=csv
Setting environment variable: TNSFRMS_ID_MOD=id_mod
Setting environment variable: TNSFRMS_TAR_PART_SIZE=268435456
Setting environment variable: HASH_METHOD_LOC=hash_keys
Setting environment variable: TNSFRMS_RES_LOC=../tests/test_tables/resources/{prodtest}/dss_entity_map_view/id_group={id_group}
Setting environment variable: TNSFRMS_RES_TYPE=csv
Default environment variables have been set where necessary.
[hash_lib] importing base classes
[hash_lib] import complete

 Transforms Library: 24 transforms available
   Use listatomic() to see all available transforms in a table format.


 Macro Library: 4 macro transforms available
   Use listmacro() to see all available macro transforms in a table format.

Production/Test mode set to: prod
Transformslib will now attempt to read in the table sources from the pre-transform summary data...
Transformslib has successfully read in the table sources.
+-----------------+----------------------------------------------------------+
|   table_name    |                        table_path                        |
+-----------------+----------------------------------------------------------+
|      state      |      ../tests/test_tables/jobs/prod/job_1/state.csv      |
| entity_multi_id | ../tests/test_tables/jobs/prod/job_1/entity_multi_id.csv |
|    location     |    ../tests/test_tables/jobs/prod/job_1/location.csv     |
|     salary      |     ../tests/test_tables/jobs/prod/job_1/salary.csv      |
|   array_like    |   ../tests/test_tables/jobs/prod/job_1/array_like.csv    |
|    positions    |    ../tests/test_tables/jobs/prod/job_1/positions.csv    |
|   date_table    |   ../tests/test_tables/jobs/prod/job_1/date_table.csv    |
|  decimal_table  |  ../tests/test_tables/jobs/prod/job_1/decimal_table.csv  |
|   types_table   |   ../tests/test_tables/jobs/prod/job_1/types_table.csv   |
+-----------------+----------------------------------------------------------+
Transformslib will now attempt to load each table in this supply...
Successfully loaded table: state
Successfully loaded table: entity_multi_id
Successfully loaded table: location
Successfully loaded table: salary
Successfully loaded table: array_like
Successfully loaded table: positions
Successfully loaded table: date_table
Successfully loaded table: decimal_table
Successfully loaded table: types_table

Successfully loaded 9 tables
Transformslib will now gather the warning messages from the pre-transform column data...
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+
| table_name | column_name |                            warning_messages                             | processing_comments | review_comments | safe_data_comments |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+
|   salary   |     age     | [schema] column found in schema with description but data type mismatch |      msg1row3       |    msg2row3     |      msg3row3      |
|   salary   |     age     |     [all] no all_pass rules matched - using default status: warning     |      msg1row3       |    msg2row3     |      msg3row3      |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+
Transformslib will now attempt to read in the data types...
SL031 Error in extracting data types: Length of 'ascending' must match length of 'by' columns.
TODO: schema validation checks against loaded tables with data types
Transformslib will now attempt to read in the list of known entity ids...
Set id_group_cd 3 for entity key 'name' in table 'location'
Set id_group_cd 3 for entity key 'name' in table 'salary'
Set id_group_cd 3 for entity key 'name' in table 'positions'
Set id_group_cd 3 for entity key 'name' in table 'date_table'
Set id_group_cd 2 for entity key 'id' in table 'date_table'

Loading the entity map...
Loaded the following tables: 
{'state': state, 'entity_multi_id': entity_multi_id, 'location': location, 'salary': salary, 'array_like': array_like, 'positions': positions, 'date_table': date_table, 'decimal_table': decimal_table, 'types_table': types_table, 'entity_map': entity_map}

========================================================================================================================
 TRANSFORMS LIBRARY - Available Transform Classes
========================================================================================================================
 Total Transforms: 24
========================================================================================================================
Transform Name     | Description
-------------------+--------------------------------------------------------------------------------------------------
Arithmetic         | Transform class for adding, divding, subtracting columns or applying an exponent
AttachSynID        | Will attach a synthetic ID to the Table from its source ID
CastColumnType     | Transform class for casting a column to a specified data type.
ComplexFilter      | Transform class for filtering rows in a DataFrame using a backend-specific condition.
ConcatColumns      | Transform class for concatenating multiple columns into a single column.
CreateColumn       | Create a column to a dataframe using a default value
DistinctTable      | Transform class for removing duplicate rows from a DataFrame.
DropNAValues       | Transform class for dropping rows with NA/None/Null values in a specified column.
DropVariable       | Transform class for removing one or more variables/columns from a DataFrame.
DuplicateColumn    | Duplicate and clone a column with an alias in your table
ExplodeColumn      | Transform class for exploding a list-like column into multiple rows.
ForceCase          | Transform class to force string values in a specified column to upper or lower case.
HashColumns        | Using the hashing tool, hash the contents of one or more columns into a new column.
JoinTable          | Transform class for joining two tables in a TableCollection.
PartitionByValue   | Transform class for partitioning a DataFrame into multiple tables
RenameTable        | Transform class for renaming columns in a DataFrame.
ReplaceByCondition | Transform class for replacing values in a column based on a comparison condition.
RoundNumber        | Transform class to round numeric values in a specified column to a given number of decimal pla...
SimpleFilter       | Transform class for filtering rows in a DataFrame using a simple column comparison.
SortTable          | Transform class to sort a table by one or more columns.
SubsetTable        | Transform class for subsetting a DataFrame to retain only specified columns.
TrimWhitespace     | Transform class for trimming leading and trailing whitespace from string values in a specified...
TruncateDate       | Transform class to truncate date values in a specified column to year or month level.
UnionTables        | Transform class to perform a union of two tables with matching schemas.
========================================================================================================================
 Use help(ClassName) for detailed information about any transform.
========================================================================================================================


========================================================================================================================
 MACRO LIBRARY - Available Macro Transform Classes
========================================================================================================================
 Total Macro Transforms: 4
========================================================================================================================
Macro Name        | Description
------------------+---------------------------------------------------------------------------------------------------
ApplyLegacyIDHash | Transform class to apply specific HMAC hashing to a specified column using a secret key.
ConcatenateIDs    | A macro that concatenates two ID columns with an underscore separator.
DropMissingIDs    | A macro that drops missing IDs from a table by removing rows with NA values in the synthetic va...
TopBottomCode     | A macro that applies top and bottom coding to specified variables in a table collection.
========================================================================================================================
 Use help(ClassName) for detailed information about any macro transform.
========================================================================================================================

+-----------+--------+--------------+--------------+-----------------+
|id_group_cd|  src_id|syn_id_refresh|syn_id_interim|post_worm_cutover|
+-----------+--------+--------------+--------------+-----------------+
|          2|       3|            31|           313|             true|
|          2|       1|            12|           114|            false|
|          2|       2|            21|           212|            false|
|          3|John Doe|           101|          1011|            false|
|          3|  Twiggy|           303|          3031|            false|
+-----------+--------+--------------+--------------+-----------------+

Cloning a column.. Pre-transformation:
+------+-----------+---+
|salary|       name|age|
+------+-----------+---+
|   400|   John Doe|  1|
|   500| Jane Smith|  4|
|   600|Bob Johnson|  1|
|   600|     Twiggy|  1|
|   620|     Finley|  1|
|   700|      Peggy|  5|
+------+-----------+---+

we should expect a cloned column and a new column of 5s
+------+-----------+---+------------+------------------+
|salary|       name|age|salary_clone|new_column_of_five|
+------+-----------+---+------------+------------------+
|   400|   John Doe|  1|         400|                 5|
|   500| Jane Smith|  4|         500|                 5|
|   600|Bob Johnson|  1|         600|                 5|
|   600|     Twiggy|  1|         600|                 5|
|   620|     Finley|  1|         620|                 5|
|   700|      Peggy|  5|         700|                 5|
+------+-----------+---+------------+------------------+

adding new values together in salary table to give us 10
subtracting new values should give us 0
multiply new values should give us 50
exponent of new values should give us 3125
divide of new values should give us 625
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|       name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   400|   John Doe|  1|         400|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   500| Jane Smith|  4|         500|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   600|Bob Johnson|  1|         600|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   600|     Twiggy|  1|         600|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   620|     Finley|  1|         620|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   700|      Peggy|  5|         700|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Partitioning salary by salary
Table: salary_700
+------+-----+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary| name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+-----+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   700|Peggy|  5|         700|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+-----+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Table: salary_620
+------+------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|  name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   620|Finley|  1|         620|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Table: salary_500
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|      name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   500|Jane Smith|  4|         500|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Table: salary_600
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|       name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   600|Bob Johnson|  1|         600|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   600|     Twiggy|  1|         600|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+-----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
                                                                                
System.Management.Automation.RemoteException
[Stage 192:>                                                        (0 + 1) / 1]
System.Management.Automation.RemoteException

Table: salary_400
+------+--------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|    name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+--------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   400|John Doe|  1|         400|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+--------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Casting tests on various types
Casting integer types
Original columns (positions): ['age', 'name', 'var', 'position', 'skill']
After DropVariable (var) on positions: ['age', 'name', 'position', 'skill']
+----+----------------+--------+------+
| age|            name|position| skill|
+----+----------------+--------+------+
|   1|        John Doe|   front|  high|
|   2|      Jane Smith|    back|medium|
|   3|     Bob Johnson|  middle|   low|
|   3|     Bob Johnson|   front|   low|
|   4|          Twiggy|   front|   low|
|NULL|Alice Wonderland|    back|  NULL|
+----+----------------+--------+------+

Original columns (salary): ['salary', 'name', 'age', 'salary_clone', 'new_column_of_five', 'new_column_of_ten', 'new_column_of_zero', 'new_column_of_fifty', 'new_exponent_result', 'new_divide_result']
After SubsetTable (keep salary) on salary: ['salary', 'age']
+------+---+
|salary|age|
+------+---+
|   400|  1|
|   500|  4|
|   600|  1|
|   600|  1|
|   620|  1|
|   700|  5|
+------+---+

Applying DistinctTable on positions
After DistinctTable on positions (all columns):
+----+----------------+--------+------+
| age|            name|position| skill|
+----+----------------+--------+------+
|   4|          Twiggy|   front|   low|
|   1|        John Doe|   front|  high|
|   2|      Jane Smith|    back|medium|
|   3|     Bob Johnson|  middle|   low|
|   3|     Bob Johnson|   front|   low|
|NULL|Alice Wonderland|    back|  NULL|
+----+----------------+--------+------+

Applying DistinctTable on salary
After DistinctTable on salary (all columns):
+------+---+
|salary|age|
+------+---+
|   620|  1|
|   400|  1|
|   700|  5|
|   600|  1|
|   500|  4|
+------+---+

Original columns (salary): ['salary', 'age']
After RenameTable (salary -> income) on salary: ['income', 'age']
+------+---+
|income|age|
+------+---+
|   620|  1|
|   400|  1|
|   700|  5|
|   600|  1|
|   500|  4|
+------+---+

Applying ComplexFilter (income >= 600) on salary
After ComplexFilter (income > 600) on salary:
+------+---+
|income|age|
+------+---+
|   620|  1|
|   700|  5|
|   600|  1|
+------+---+

Joining positions and salary on age
After JoinTable (positions inner join salary on age):
+---+--------+--------+-----+------+
|age|    name|position|skill|income|
+---+--------+--------+-----+------+
|  1|John Doe|   front| high|   600|
|  1|John Doe|   front| high|   620|
+---+--------+--------+-----+------+

Applying SimpleFilter (income > 600) on example_join
After SimpleFilter:
+---+--------+--------+-----+------+
|age|    name|position|skill|income|
+---+--------+--------+-----+------+
|  1|John Doe|   front| high|   620|
+---+--------+--------+-----+------+

Concatenating variables
NamedList(['age', 'skill'])
_
After ConcatColumns (age, skill -> concatted) on example_join:
+---+--------+--------+-----+------+---------+
|age|    name|position|skill|income|concatted|
+---+--------+--------+-----+------+---------+
|  1|John Doe|   front| high|   620|   1_high|
+---+--------+--------+-----+------+---------+

Replacing values in income where income >= 610 with 600
After ReplaceByCondition (income >= 610 -> 600):
+---+--------+--------+-----+------+---------+
|age|    name|position|skill|income|concatted|
+---+--------+--------+-----+------+---------+
|  1|John Doe|   front| high|   600|   1_high|
+---+--------+--------+-----+------+---------+

Exploding an array type test
+----+----+-----+
|var1|var2| var3|
+----+----+-----+
|   a|   b|    c|
|   a|   b|    d|
|   a|   b|    e|
|   g|   h|    j|
|   a|   f|    s|
|   f|   g|    a|
|   f|   g|    b|
|   f|   g|    d|
|   k|   l|    m|
|   k|   l|    n|
|   k|   l|    o|
|   k|   l|pppps|
+----+----+-----+

Rounding a number to 3 decimal places
+------+------+------+
|value1|value2|value3|
+------+------+------+
|     a| 0.154|  24.2|
|     b| 24.12|    24|
+------+------+------+

Truncating a date to year and month levels
+---+-------+-------------------+
| id|   name|         event_date|
+---+-------+-------------------+
|  1|  Alice|2025-01-01 00:00:00|
|  2|    Bob|2023-03-01 00:00:00|
|  3|Charlie|2023-07-01 00:00:00|
|  4|  Diana|2023-10-01 00:00:00|
|  5|  Ethan|2023-12-01 00:00:00|
+---+-------+-------------------+

+---+-------+-------------------+
| id|   name|         event_date|
+---+-------+-------------------+
|  1|  Alice|2025-01-01 00:00:00|
|  2|    Bob|2023-01-01 00:00:00|
|  3|Charlie|2023-01-01 00:00:00|
|  4|  Diana|2023-01-01 00:00:00|
|  5|  Ethan|2023-01-01 00:00:00|
+---+-------+-------------------+

Sorting the date_table by event_date
+---+-------+-------------------+
| id|   name|         event_date|
+---+-------+-------------------+
|  2|    Bob|2023-01-01 00:00:00|
|  3|Charlie|2023-01-01 00:00:00|
|  4|  Diana|2023-01-01 00:00:00|
|  5|  Ethan|2023-01-01 00:00:00|
|  1|  Alice|2025-01-01 00:00:00|
+---+-------+-------------------+

Applying ForceCase (upper) on var2 column
After ForceCase (upper):
+----+----+-----+
|var1|var2| var3|
+----+----+-----+
|   a|   B|    c|
|   a|   B|    d|
|   a|   B|    e|
|   g|   H|    j|
|   a|   F|    s|
|   f|   G|    a|
|   f|   G|    b|
|   f|   G|    d|
|   k|   L|    m|
|   k|   L|    n|
|   k|   L|    o|
|   k|   L|pppps|
+----+----+-----+

Applying TrimWhitespace on name column
After TrimWhitespace:
+-----------+---------+---------+-------+
|       name|     city|  country| region|
+-----------+---------+---------+-------+
|   John Doe| New York|      USA|   East|
| Jane Smith|   London|       UK|   West|
|Bob Johnson|   Sydney|Australia|  South|
|Bob Johnson|  Toronto|   Canada|  North|
|     Twiggy|    Paris|   France|Central|
|Spaced Name|Melbourne|Australia|  South|
+-----------+---------+---------+-------+

Applying TopBottomCode macro to salary column
Original salary data:
+------+---+
|income|age|
+------+---+
|   500|  1|
|   500|  5|
|   500|  1|
+------+---+

Applying UnionTables on two salary tables (with and without duplicates)
After UnionTables (salary_400 and salary_500):
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|salary|      name|age|salary_clone|new_column_of_five|new_column_of_ten|new_column_of_zero|new_column_of_fifty|new_exponent_result|new_divide_result|
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+
|   400|  John Doe|  1|         400|                 5|               10|                 0|                 50|             3125.0|            625.0|
|   500|Jane Smith|  4|         500|                 5|               10|                 0|                 50|             3125.0|            625.0|
+------+----------+---+------------+------------------+-----------------+------------------+-------------------+-------------------+-----------------+

Applying AttachSynID on name column
+---------+---------+-------+------+
|     city|  country| region|syn_id|
+---------+---------+-------+------+
| New York|      USA|   East|  1011|
|   London|       UK|   West|  NULL|
|   Sydney|Australia|  South|  NULL|
|  Toronto|   Canada|  North|  NULL|
|    Paris|   France|Central|  3031|
|Melbourne|Australia|  South|  NULL|
+---------+---------+-------+------+

Applying hashing test
Loading config files for hashing...
Initialising hashing method: hextest
Hashing method initialised with key: 417PwOkc1r7Ou2MRksUhQ3GKe63aFss6kwFphfd5Mp8= and truncation length: 16, output format: hex
Performing integrity check on hash key...
Key passed checksum.
region
+---------+---------+----------------+------+
|     city|  country|          region|syn_id|
+---------+---------+----------------+------+
| New York|      USA|a57ef3b30f31625b|  1011|
|   London|       UK|5980592d8b6c8700|  NULL|
|   Sydney|Australia|24ec8862fda8a568|  NULL|
|  Toronto|   Canada|726576d30dedd980|  NULL|
|    Paris|   France|a448bea7acb467ea|  3031|
|Melbourne|Australia|24ec8862fda8a568|  NULL|
+---------+---------+----------------+------+

Setting minimum value to 450 and maximum value to 650
After TopBottomCode transformation:
+------+---+
|income|age|
+------+---+
|   500|  1|
|   500|  5|
|   500|  1|
+------+---+

Testing MetaFrame metadata tracking (warning_messages and person_keys)

Formatted info for 'salary' table:

Table: salary (3 rows) ID Group Code: 3
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+
| table_name | column_name |                            warning_messages                             | processing_comments | review_comments | safe_data_comments | person_key |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+
|   salary   |     age     | [schema] column found in schema with description but data type mismatch |      msg1row3       |    msg2row3     |      msg3row3      |            |
|   salary   |     age     |     [all] no all_pass rules matched - using default status: warning     |      msg1row3       |    msg2row3     |      msg3row3      |            |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+

Formatted info for 'location' table:

Table: location (6 rows) ID Group Code: 3
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|    city     |            |
|   country   |            |
|   region    |            |
|   syn_id    |            |
+-------------+------------+
-------------------------------

Info for all tables via TableCollection.get_info():

Table: state (5 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|    city     |            |
|    state    |            |
+-------------+------------+


Table: entity_multi_id (10 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|  id_part1   |            |
|  id_part2   |            |
+-------------+------------+


Table: location (6 rows) ID Group Code: 3
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|    city     |            |
|   country   |            |
|   region    |            |
|   syn_id    |            |
+-------------+------------+


Table: salary (3 rows) ID Group Code: 3
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+
| table_name | column_name |                            warning_messages                             | processing_comments | review_comments | safe_data_comments | person_key |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+
|   salary   |     age     | [schema] column found in schema with description but data type mismatch |      msg1row3       |    msg2row3     |      msg3row3      |            |
|   salary   |     age     |     [all] no all_pass rules matched - using default status: warning     |      msg1row3       |    msg2row3     |      msg3row3      |            |
+------------+-------------+-------------------------------------------------------------------------+---------------------+-----------------+--------------------+------------+


Table: array_like (12 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|    var1     |            |
|    var2     |            |
|    var3     |            |
+-------------+------------+


Table: positions (6 rows) ID Group Code: 3
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|     age     |            |
|    name     |            |
|  position   |            |
|    skill    |            |
+-------------+------------+


Table: date_table (5 rows) ID Group Code: 2
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|     id      |            |
|    name     |            |
| event_date  |            |
+-------------+------------+


Table: decimal_table (2 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|   value1    |            |
|   value2    |            |
|   value3    |            |
+-------------+------------+


Table: types_table (2 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|   string    |            |
|   float1    |            |
|   float2    |            |
|     int     |            |
+-------------+------------+


Table: entity_map (5 rows) ID Group Code: N/A
+-------------------+------------+
|    column_name    | person_key |
+-------------------+------------+
|    id_group_cd    |            |
|      src_id       |            |
|  syn_id_refresh   |            |
|  syn_id_interim   |            |
| post_worm_cutover |            |
+-------------------+------------+


Table: salary_700 (1 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
+---------------------+------------+


Table: salary_620 (1 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
+---------------------+------------+


Table: salary_500 (1 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
+---------------------+------------+


Table: salary_600 (2 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
                                                                                
System.Management.Automation.RemoteException
[Stage 476:>                                                        (0 + 1) / 1]
System.Management.Automation.RemoteException
+---------------------+------------+


Table: salary_400 (1 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
+---------------------+------------+


Table: example_join (1 rows) ID Group Code: N/A
+-------------+------------+
| column_name | person_key |
+-------------+------------+
|     age     |            |
|    name     |            |
|  position   |            |
|    skill    |            |
|   income    |            |
|  concatted  |            |
+-------------+------------+


Table: salary_union (2 rows) ID Group Code: N/A
+---------------------+------------+
|     column_name     | person_key |
+---------------------+------------+
|       salary        |            |
|        name         |            |
|         age         |            |
|    salary_clone     |            |
| new_column_of_five  |            |
|  new_column_of_ten  |            |
| new_column_of_zero  |            |
| new_column_of_fifty |            |
| new_exponent_result |            |
|  new_divide_result  |            |
+---------------------+------------+

Applying DropNAValues on salary table
Before DropNAValues on age column in positions table:
+----+----------------+--------+------+
| age|            name|position| skill|
+----+----------------+--------+------+
|   4|          Twiggy|   front|   low|
|   1|        John Doe|   front|  high|
|   2|      Jane Smith|    back|medium|
|   3|     Bob Johnson|  middle|   low|
|   3|     Bob Johnson|   front|   low|
|NULL|Alice Wonderland|    back|  NULL|
+----+----------------+--------+------+

After DropNAValues on age column in positions table:
+---+-----------+--------+------+
|age|       name|position| skill|
+---+-----------+--------+------+
|  4|     Twiggy|   front|   low|
|  1|   John Doe|   front|  high|
|  2| Jane Smith|    back|medium|
|  3|Bob Johnson|  middle|   low|
|  3|Bob Johnson|   front|   low|
+---+-----------+--------+------+

Applying ConcatenateIDs macro to multi-id tables
+--------+--------+
|id_part1|id_part2|
+--------+--------+
|       1|       2|
|       2|       1|
|       3|       4|
|       5|       1|
|       7|      12|
|      14|       4|
|       7|    NULL|
|    NULL|       4|
|    NULL|       6|
|      19|       1|
+--------+--------+

NamedList(['id_part1', 'id_part2'])
_
['entity_multi_id']
+--------+--------+-------+
|id_part1|id_part2|full_id|
+--------+--------+-------+
|       1|       2|    1_2|
|       2|       1|    2_1|
|       3|       4|    3_4|
|       5|       1|    5_1|
|       7|      12|   7_12|
|      14|       4|   14_4|
|       7|    NULL|      7|
|    NULL|       4|      4|
|    NULL|       6|      6|
|      19|       1|   19_1|
+--------+--------+-------+

Drop missing IDs from tables using DropMissingIDs macro
Testing on the location table that should have synthetic IDs
+---------+---------+----------------+------+
|     city|  country|          region|syn_id|
+---------+---------+----------------+------+
| New York|      USA|a57ef3b30f31625b|  1011|
|   London|       UK|5980592d8b6c8700|  NULL|
|   Sydney|Australia|24ec8862fda8a568|  NULL|
|  Toronto|   Canada|726576d30dedd980|  NULL|
|    Paris|   France|a448bea7acb467ea|  3031|
|Melbourne|Australia|24ec8862fda8a568|  NULL|
+---------+---------+----------------+------+

+--------+-------+----------------+------+
|    city|country|          region|syn_id|
+--------+-------+----------------+------+
|New York|    USA|a57ef3b30f31625b|  1011|
|   Paris| France|a448bea7acb467ea|  3031|
+--------+-------+----------------+------+


example of final table going through some tests
first join complete
+--------+-------+----------------+------+----------------+
|    city|country|          region|syn_id|           state|
+--------+-------+----------------+------+----------------+
|New York|    USA|a57ef3b30f31625b|  1011|        New York|
|   Paris| France|a448bea7acb467ea|  3031|Island of France|
|  Sydney|   NULL|            NULL|  NULL|             NSW|
|  London|   NULL|            NULL|  NULL|         England|
| Toronto|   NULL|            NULL|  NULL|         Ontario|
+--------+-------+----------------+------+----------------+

Saving all tables: ['salary_700', 'salary_620', 'salary_500', 'salary_600', 'salary_400', 'salary', 'salary_union']

Writing to jobs/prod/job_1/salary_700 as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary_620 as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary_500 as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary_600 as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary_400 as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary as parquet with mode=overwrite (compression=zstd)
Writing to jobs/prod/job_1/salary_union as parquet with mode=overwrite (compression=zstd)
save events for table salary_700
Events saved to jobs/prod/job_1/debug_salary_700_events.json
save events for table salary_620
Events saved to jobs/prod/job_1/debug_salary_620_events.json
save events for table salary_500
Events saved to jobs/prod/job_1/debug_salary_500_events.json
save events for table salary_600
Events saved to jobs/prod/job_1/debug_salary_600_events.json
save events for table salary_400
Events saved to jobs/prod/job_1/debug_salary_400_events.json
save events for table salary
Events saved to jobs/prod/job_1/debug_salary_events.json
save events for table salary_union
Events saved to jobs/prod/job_1/debug_salary_400_events.json
Subset of tables with prefix 'salary' saved successfully
Test pipeline execution completed at Sat Jan 24 03:08:01 2026
Total execution time: 76.09 seconds
Spark session stopped successfully
SUCCESS: The process with PID 17724 (child process of PID 23712) has been terminated.
SUCCESS: The process with PID 23712 (child process of PID 17416) has been terminated.
SUCCESS: The process with PID 17416 (child process of PID 17752) has been terminated.
                                                                                
 
 
================================================================================ 
Running: make_dag.py 
================================================================================ 
 
Starting test pipeline execution at Sat Jan 24 03:08:05 2026
Setting environment variable: TNSFRMS_EXE_ENGINE=pyspark
Setting environment variable: TNSFRMS_JOB_ID=-1
Setting environment variable: TNSFRMS_RUN_ID=-1
Setting environment variable: TNSFRMS_PROD=prod
Setting environment variable: TNSFRMS_LOG_LOC=jobs/{prodtest}/job_{job_id}/treatments.json
Setting environment variable: TNSFRMS_OUT_TABLE_LOC=jobs/{prodtest}/job_{job_id}
Setting environment variable: TNSFRMS_SRC_VAR=src_id
Setting environment variable: TNSFRMS_SYN_VAR=syn_id
Setting environment variable: TNSFRMS_ID_VAR=per_id
Setting environment variable: TNSFRMS_IDMAPS_LOC=../tests/test_tables/id_maps
Setting environment variable: TNSFRMS_JOB_STATE=../tests/test_tables/jobs/{prodtest}/job_{job_id}/setup/run_state.json
Setting environment variable: TNSFRMS_JOB_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/{tablename}.json
Setting environment variable: TNSFRMS_JOB_COLS_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_columns.csv
Setting environment variable: TNSFRMS_TABLE_SUMMARY_PATH=../tests/test_tables/jobs/{prodtest}/job_{job_id}/pre_transform_table_summary.csv
Setting environment variable: TNSFRMS_SUPPLY_LOAD_FORMAT=csv
Setting environment variable: TNSFRMS_ID_MOD=id_mod
Setting environment variable: TNSFRMS_TAR_PART_SIZE=268435456
Setting environment variable: HASH_METHOD_LOC=hash_keys
Setting environment variable: TNSFRMS_RES_LOC=../tests/test_tables/resources/{prodtest}/dss_entity_map_view/id_group={id_group}
Setting environment variable: TNSFRMS_RES_TYPE=csv
Default environment variables have been set where necessary.
Production/Test mode set to: prod
DAG saved to: transform_dags/transform_dag_job1_run1.html
Test pipeline execution completed at Sat Jan 24 03:08:24 2026
Total execution time: 19.11 seconds
Searching in "..\..\templates\jobs\prod\job_1" ...
OK: No metadata files found.
